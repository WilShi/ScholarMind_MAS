"""
ScholarMind Pipeline
æ™ºè¯»ScholarMindå·¥ä½œæµ
"""

import asyncio
import time
from typing import Any, Dict, List, Optional

from agentscope import pipeline
from agentscope.message import Msg

from ..agents.resource_retrieval_agent import ResourceRetrievalAgent
from ..agents.methodology_agent import MethodologyAgent
from ..agents.experiment_evaluator_agent import ExperimentEvaluatorAgent
from ..agents.insight_generation_agent import InsightGenerationAgent
from ..agents.synthesizer_agent import SynthesizerAgent
from ..utils.logger import pipeline_logger


class ScholarMindPipeline:
    """ScholarMindå·¥ä½œæµ"""

    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        pipeline_logger.info("åˆå§‹åŒ–ScholarMindå·¥ä½œæµ...")

        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.resource_agent = ResourceRetrievalAgent()
        self.methodology_agent = MethodologyAgent()
        self.experiment_agent = ExperimentEvaluatorAgent()
        self.insight_agent = InsightGenerationAgent()
        self.synthesizer_agent = SynthesizerAgent()

        # åˆ›å»ºå®Œæ•´DAGå·¥ä½œæµï¼ˆ5ä¸ªæ™ºèƒ½ä½“ï¼‰
        # Stage 1: Resource Retrieval (sequential)
        # Stage 2: Methodology + Experiment (parallel)
        # Stage 3: Insight Generation (sequential, uses results from Stage 2)
        # Stage 4: Synthesizer (sequential, integrates all results)
        self.pipeline = pipeline.SequentialPipeline(
            agents=[
                self.resource_agent,
                # Parallel and insight agents will be handled in process_paper method
                self.synthesizer_agent
            ]
        )
        self.pipeline.name = "scholarmind_phase3_pipeline"

        pipeline_logger.info("å·¥ä½œæµåˆå§‹åŒ–å®Œæˆï¼ˆ5ä¸ªæ™ºèƒ½ä½“å®Œæ•´DAGï¼‰")

    async def process_paper(
        self,
        paper_input: str,
        input_type: str = "file",
        user_background: str = "intermediate",
        save_report: bool = True,
        output_format: str = "markdown",
        output_language: str = "zh",
        progress_callback: Optional[callable] = None,
    ) -> Dict[str, Any]:
        """
        å¤„ç†è®ºæ–‡çš„å®Œæ•´æµç¨‹ï¼ˆ5ä¸ªæ™ºèƒ½ä½“å®Œæ•´DAGï¼‰

        Args:
            paper_input: è®ºæ–‡è¾“å…¥ï¼ˆæ–‡ä»¶è·¯å¾„ã€URLæˆ–æ–‡æœ¬ï¼‰
            input_type: è¾“å…¥ç±»å‹ï¼ˆfileã€urlã€textï¼‰
            user_background: ç”¨æˆ·èƒŒæ™¯ï¼ˆbeginnerã€intermediateã€advancedï¼‰
            save_report: æ˜¯å¦ä¿å­˜æŠ¥å‘Š
            output_format: è¾“å‡ºæ ¼å¼ï¼ˆmarkdownã€jsonï¼‰
            output_language: è¾“å‡ºè¯­è¨€ï¼ˆzhã€enï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œç”¨äºæ›´æ–°è¿›åº¦ä¿¡æ¯

        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœ
        """
        start_time = time.time()

        try:
            # å‘é€è¿›åº¦ï¼šå¼€å§‹å¤„ç†
            if progress_callback:
                await progress_callback(f"ğŸ“¥ å¼€å§‹å¤„ç†è®ºæ–‡ï¼ˆè¾“å…¥ç±»å‹: {input_type}ï¼‰...")
            else:
                pipeline_logger.info(f"å¼€å§‹å¤„ç†è®ºæ–‡ï¼Œè¾“å…¥ç±»å‹: {input_type}")

            # æ­¥éª¤1ï¼šèµ„æºæ£€ç´¢
            if progress_callback:
                await progress_callback("ğŸ“– æ­¥éª¤ 1/4ï¼šæ­£åœ¨æ£€ç´¢å’Œè§£æè®ºæ–‡...")
            else:
                pipeline_logger.info("æ­¥éª¤1ï¼šèµ„æºæ£€ç´¢...")
            resource_result = await self._process_resource_retrieval(paper_input, input_type)

            if not resource_result["success"]:
                if progress_callback:
                    await progress_callback(f"âŒ èµ„æºæ£€ç´¢å¤±è´¥: {resource_result['error']}")
                return {
                    "success": False,
                    "error": f"èµ„æºæ£€ç´¢å¤±è´¥: {resource_result['error']}",
                    "stage": "resource_retrieval",
                }

            # æ­¥éª¤2ï¼šå¹¶è¡Œå¤„ç†ï¼ˆæ–¹æ³•è®ºåˆ†æ + å®éªŒè¯„ä¼°ï¼‰
            if progress_callback:
                await progress_callback("ğŸ”¬ æ­¥éª¤ 2/4ï¼šå¹¶è¡Œåˆ†æè®ºæ–‡æ–¹æ³•è®ºå’Œå®éªŒè¯„ä¼°...")
            else:
                pipeline_logger.info("æ­¥éª¤2ï¼šå¹¶è¡Œåˆ†æï¼ˆæ–¹æ³•è®º + å®éªŒè¯„ä¼°ï¼‰...")
            parallel_start = time.time()

            methodology_result, experiment_result = await self._process_parallel_analysis(
                resource_result["data"]["paper_content"], output_language
            )

            parallel_time = time.time() - parallel_start
            if progress_callback:
                await progress_callback(f"âœ… å¹¶è¡Œåˆ†æå®Œæˆï¼Œè€—æ—¶: {parallel_time:.1f}ç§’")
            else:
                pipeline_logger.info(f"å¹¶è¡Œåˆ†æå®Œæˆï¼Œè€—æ—¶: {parallel_time:.2f}ç§’")

            # æ£€æŸ¥å¹¶è¡Œå¤„ç†ç»“æœ
            if not methodology_result["success"]:
                if progress_callback:
                    await progress_callback(f"âš ï¸  æ–¹æ³•è®ºåˆ†æå¤±è´¥: {methodology_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    pipeline_logger.warning(f"æ–¹æ³•è®ºåˆ†æå¤±è´¥: {methodology_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            if not experiment_result["success"]:
                if progress_callback:
                    await progress_callback(f"âš ï¸  å®éªŒè¯„ä¼°å¤±è´¥: {experiment_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    pipeline_logger.warning(f"å®éªŒè¯„ä¼°å¤±è´¥: {experiment_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # æ­¥éª¤3ï¼šæ´å¯Ÿç”Ÿæˆï¼ˆåŸºäºå‰é¢çš„åˆ†æç»“æœï¼‰
            if progress_callback:
                await progress_callback("ğŸ’¡ æ­¥éª¤ 3/4ï¼šç”Ÿæˆæ‰¹åˆ¤æ€§æ´å¯Ÿå’Œç ”ç©¶å»ºè®®...")
            else:
                pipeline_logger.info("æ­¥éª¤3ï¼šæ´å¯Ÿç”Ÿæˆ...")
            insight_result = await self._process_insight_generation(
                resource_result["data"]["paper_content"],
                methodology_result.get("data") if methodology_result["success"] else None,
                experiment_result.get("data") if experiment_result["success"] else None,
                output_language
            )

            if not insight_result["success"]:
                if progress_callback:
                    await progress_callback(f"âš ï¸  æ´å¯Ÿç”Ÿæˆå¤±è´¥: {insight_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    pipeline_logger.warning(f"æ´å¯Ÿç”Ÿæˆå¤±è´¥: {insight_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # æ­¥éª¤4ï¼šç»¼åˆæŠ¥å‘Šç”Ÿæˆ
            if progress_callback:
                await progress_callback("ğŸ“ æ­¥éª¤ 4/4ï¼šç»¼åˆç”Ÿæˆä¸ªæ€§åŒ–è§£è¯»æŠ¥å‘Š...")
            else:
                pipeline_logger.info("æ­¥éª¤4ï¼šç»¼åˆæŠ¥å‘Šç”Ÿæˆ...")
            synthesizer_result = await self._process_synthesizer(
                resource_result["data"],
                methodology_result.get("data") if methodology_result["success"] else None,
                experiment_result.get("data") if experiment_result["success"] else None,
                insight_result.get("data") if insight_result["success"] else None,
                user_background,
                output_language
            )

            if not synthesizer_result["success"]:
                if progress_callback:
                    await progress_callback(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {synthesizer_result['error']}")
                return {
                    "success": False,
                    "error": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {synthesizer_result['error']}",
                    "stage": "synthesizer",
                }

            # æ­¥éª¤5ï¼šä¿å­˜æŠ¥å‘Šï¼ˆå¦‚æœéœ€è¦ï¼‰
            report_path = None
            if save_report:
                if progress_callback:
                    await progress_callback("ğŸ’¾ æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
                report_path = self._save_report(synthesizer_result["data"], output_format, output_language)

            # è®¡ç®—æ€»å¤„ç†æ—¶é—´
            total_time = time.time() - start_time

            # å‘é€å®Œæˆæ¶ˆæ¯
            if progress_callback:
                await progress_callback(f"âœ¨ è®ºæ–‡åˆ†æå®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")

            # æ„å»ºæœ€ç»ˆç»“æœ
            result = {
                "success": True,
                "message": "è®ºæ–‡å¤„ç†å®Œæˆ",
                "processing_time": total_time,
                "stages": {
                    "resource_retrieval": {
                        "success": True,
                        "processing_time": resource_result["processing_time"],
                        "paper_title": resource_result["data"]["paper_content"]["metadata"]["title"],
                    },
                    "methodology_analysis": {
                        "success": methodology_result["success"],
                        "processing_time": methodology_result.get("processing_time", 0),
                    },
                    "experiment_evaluation": {
                        "success": experiment_result["success"],
                        "processing_time": experiment_result.get("processing_time", 0),
                    },
                    "parallel_processing_time": parallel_time,
                    "insight_generation": {
                        "success": insight_result["success"],
                        "processing_time": insight_result.get("processing_time", 0),
                    },
                    "synthesizer": {
                        "success": True,
                        "processing_time": synthesizer_result["processing_time"],
                        "report_title": synthesizer_result["data"]["title"],
                    },
                },
                "outputs": {
                    "paper_content": resource_result["data"]["paper_content"],
                    "methodology_analysis": methodology_result.get("data") if methodology_result["success"] else None,
                    "experiment_evaluation": experiment_result.get("data") if experiment_result["success"] else None,
                    "insight_analysis": insight_result.get("data") if insight_result["success"] else None,
                    "report": synthesizer_result["data"],
                    "report_path": report_path,
                },
                "metadata": {
                    "user_background": user_background,
                    "input_type": input_type,
                    "output_format": output_format,
                    "output_language": output_language,
                },
            }

            pipeline_logger.info(f"è®ºæ–‡å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
            return result

        except Exception as e:
            total_time = time.time() - start_time
            if progress_callback:
                await progress_callback(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            else:
                pipeline_logger.error(f"è®ºæ–‡å¤„ç†å¤±è´¥: {str(e)}")

            return {"success": False, "error": str(e), "processing_time": total_time, "stage": "unknown"}

    async def _process_resource_retrieval(self, paper_input: str, input_type: str) -> Dict[str, Any]:
        """å¤„ç†èµ„æºæ£€ç´¢é˜¶æ®µ"""
        try:
            # åˆ›å»ºè¾“å…¥æ¶ˆæ¯ - ç›´æ¥ä¼ é€’å­—å…¸
            input_data = {"paper_input": paper_input, "input_type": input_type}

            message = Msg(name="user", content=input_data, role="user")

            # æ‰§è¡Œèµ„æºæ£€ç´¢
            response = await self.resource_agent.reply(message)
            response_data = response.content  # ç›´æ¥è®¿é—®å­—å…¸ï¼Œæ— éœ€json.loads

            if response_data["status"] == "success":
                return {
                    "success": True,
                    "data": response_data["data"],
                    "processing_time": response_data["data"]["processing_info"]["processing_time"],
                }
            else:
                return {"success": False, "error": response_data.get("error", "æœªçŸ¥é”™è¯¯"), "processing_time": 0}

        except Exception as e:
            return {"success": False, "error": str(e), "processing_time": 0}

    async def _process_parallel_analysis(
        self, paper_content: Dict[str, Any], output_language: str
    ) -> tuple[Dict[str, Any], Dict[str, Any]]:
        """
        å¹¶è¡Œå¤„ç†æ–¹æ³•è®ºåˆ†æå’Œå®éªŒè¯„ä¼°

        Args:
            paper_content: è®ºæ–‡å†…å®¹
            output_language: è¾“å‡ºè¯­è¨€

        Returns:
            tuple[Dict[str, Any], Dict[str, Any]]: (æ–¹æ³•è®ºåˆ†æç»“æœ, å®éªŒè¯„ä¼°ç»“æœ)
        """
        # åˆ›å»ºä¸¤ä¸ªå¹¶è¡Œä»»åŠ¡
        methodology_task = self._process_methodology(paper_content, output_language)
        experiment_task = self._process_experiment_evaluation(paper_content, output_language)

        # ä½¿ç”¨asyncio.gatherå¹¶è¡Œæ‰§è¡Œ
        methodology_result, experiment_result = await asyncio.gather(
            methodology_task,
            experiment_task,
            return_exceptions=True
        )

        # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
        if isinstance(methodology_result, Exception):
            methodology_result = {
                "success": False,
                "error": str(methodology_result),
                "processing_time": 0
            }

        if isinstance(experiment_result, Exception):
            experiment_result = {
                "success": False,
                "error": str(experiment_result),
                "processing_time": 0
            }

        return methodology_result, experiment_result

    async def _process_methodology(self, paper_content: Dict[str, Any], output_language: str) -> Dict[str, Any]:
        """å¤„ç†æ–¹æ³•è®ºåˆ†æé˜¶æ®µ"""
        try:
            # åˆ›å»ºè¾“å…¥æ¶ˆæ¯ - ç›´æ¥ä¼ é€’å­—å…¸
            input_data = {
                "paper_content": paper_content,
                "output_language": output_language,
            }

            message = Msg(name="user", content=input_data, role="user")

            # æ‰§è¡Œæ–¹æ³•è®ºåˆ†æ
            response = await self.methodology_agent.reply(message)
            response_data = response.content  # ç›´æ¥è®¿é—®å­—å…¸

            if response_data["status"] == "success":
                return {
                    "success": True,
                    "data": response_data["data"],
                    "processing_time": response_data["data"]["processing_time"],
                }
            else:
                return {"success": False, "error": response_data.get("error", "æœªçŸ¥é”™è¯¯"), "processing_time": 0}

        except Exception as e:
            return {"success": False, "error": str(e), "processing_time": 0}

    async def _process_experiment_evaluation(self, paper_content: Dict[str, Any], output_language: str) -> Dict[str, Any]:
        """å¤„ç†å®éªŒè¯„ä¼°é˜¶æ®µ"""
        try:
            # åˆ›å»ºè¾“å…¥æ¶ˆæ¯ - ç›´æ¥ä¼ é€’å­—å…¸
            input_data = {
                "paper_content": paper_content,
                "output_language": output_language,
            }

            message = Msg(name="user", content=input_data, role="user")

            # æ‰§è¡Œå®éªŒè¯„ä¼°
            response = await self.experiment_agent.reply(message)
            response_data = response.content  # ç›´æ¥è®¿é—®å­—å…¸

            if response_data["status"] == "success":
                return {
                    "success": True,
                    "data": response_data["data"],
                    "processing_time": response_data["data"]["processing_time"],
                }
            else:
                return {"success": False, "error": response_data.get("error", "æœªçŸ¥é”™è¯¯"), "processing_time": 0}

        except Exception as e:
            return {"success": False, "error": str(e), "processing_time": 0}

    async def _process_insight_generation(
        self,
        paper_content: Dict[str, Any],
        methodology_data: Optional[Dict[str, Any]],
        experiment_data: Optional[Dict[str, Any]],
        output_language: str
    ) -> Dict[str, Any]:
        """å¤„ç†æ´å¯Ÿç”Ÿæˆé˜¶æ®µ"""
        try:
            # åˆ›å»ºè¾“å…¥æ¶ˆæ¯ - ç›´æ¥ä¼ é€’å­—å…¸
            input_data = {
                "paper_content": paper_content,
                "methodology_analysis": methodology_data,
                "experiment_evaluation": experiment_data,
                "output_language": output_language,
            }

            message = Msg(name="user", content=input_data, role="user")

            # æ‰§è¡Œæ´å¯Ÿç”Ÿæˆ
            response = await self.insight_agent.reply(message)
            response_data = response.content  # ç›´æ¥è®¿é—®å­—å…¸

            if response_data["status"] == "success":
                return {
                    "success": True,
                    "data": response_data["data"],
                    "processing_time": response_data["data"]["processing_time"],
                }
            else:
                return {"success": False, "error": response_data.get("error", "æœªçŸ¥é”™è¯¯"), "processing_time": 0}

        except Exception as e:
            return {"success": False, "error": str(e), "processing_time": 0}

    async def _process_synthesizer(
        self,
        paper_content_data: Dict[str, Any],
        methodology_data: Optional[Dict[str, Any]],
        experiment_data: Optional[Dict[str, Any]],
        insight_data: Optional[Dict[str, Any]],
        user_background: str,
        output_language: str
    ) -> Dict[str, Any]:
        """å¤„ç†ç»¼åˆæŠ¥å‘Šç”Ÿæˆé˜¶æ®µ"""
        try:
            # åˆ›å»ºè¾“å…¥æ¶ˆæ¯ï¼ˆåŒ…å«æ‰€æœ‰åˆ†æç»“æœï¼‰- ç›´æ¥ä¼ é€’å­—å…¸
            input_data = {
                "paper_content": paper_content_data["paper_content"],
                "user_background": user_background,
                "output_language": output_language,
                "external_info": paper_content_data.get("external_info", {}),
                "methodology_analysis": methodology_data,
                "experiment_evaluation": experiment_data,
                "insight_analysis": insight_data,
            }

            message = Msg(name="user", content=input_data, role="user")

            # æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆ
            response = await self.synthesizer_agent.reply(message)
            response_data = response.content  # ç›´æ¥è®¿é—®å­—å…¸

            if response_data["status"] == "success":
                return {
                    "success": True,
                    "data": response_data["data"],
                    "processing_time": response_data["data"]["processing_time"],
                }
            else:
                return {"success": False, "error": response_data.get("error", "æœªçŸ¥é”™è¯¯"), "processing_time": 0}

        except Exception as e:
            return {"success": False, "error": str(e), "processing_time": 0}

    def _save_report(self, report_data: Dict[str, Any], output_format: str, output_language: str = "zh") -> Optional[str]:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            import os
            from datetime import datetime

            # å¤šè¯­è¨€ç« èŠ‚æ ‡é¢˜
            section_titles = {
                "zh": {
                    "processing_time": "å¤„ç†æ—¶é—´",
                    "user_background": "ç”¨æˆ·èƒŒæ™¯é€‚é…",
                    "summary": "æ‘˜è¦",
                    "contributions": "ä¸»è¦è´¡çŒ®",
                    "methodology": "æ–¹æ³•è®ºæ¦‚è¿°",
                    "experiments": "å®éªŒæ¦‚è¿°",
                    "insights": "å…³é”®æ´å¯Ÿ"
                },
                "en": {
                    "processing_time": "Processing Time",
                    "user_background": "User Background",
                    "summary": "Summary",
                    "contributions": "Key Contributions",
                    "methodology": "Methodology Overview",
                    "experiments": "Experiment Overview",
                    "insights": "Key Insights"
                }
            }
            titles = section_titles.get(output_language, section_titles["zh"])

            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs("outputs", exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_title = "".join(c for c in report_data["title"][:50] if c.isalnum() or c in (" ", "-", "_")).rstrip()
            filename = f"{safe_title}_{timestamp}"

            if output_format == "json":
                filepath = f"outputs/{filename}.json"
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(report_data, f, ensure_ascii=False, indent=2)
            else:
                # é»˜è®¤ä¿å­˜ä¸ºmarkdown
                filepath = f"outputs/{filename}.md"
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(f"# {report_data['title']}\n\n")
                    f.write(f"**{titles['processing_time']}**: {report_data['processing_time']:.2f}s\n\n")
                    f.write(f"**{titles['user_background']}**: {report_data['user_background_adaptation']}\n\n")
                    f.write(f"## {titles['summary']}\n\n")
                    f.write(f"{report_data['summary']}\n\n")
                    f.write(f"## {titles['contributions']}\n\n")
                    for contribution in report_data["key_contributions"]:
                        f.write(f"- {contribution}\n")
                    f.write(f"\n## {titles['methodology']}\n\n")
                    f.write(f"{report_data['methodology_summary']}\n\n")
                    f.write(f"## {titles['experiments']}\n\n")
                    f.write(f"{report_data['experiment_summary']}\n\n")
                    f.write(f"## {titles['insights']}\n\n")
                    for insight in report_data["insights"]:
                        f.write(f"- {insight}\n")

            pipeline_logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filepath}")
            return filepath

        except Exception as e:
            pipeline_logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return None

    def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        return {
            "name": self.pipeline.name,
            "agents": [
                {"name": self.resource_agent.name, "type": "ResourceRetrievalAgent"},
                {"name": self.methodology_agent.name, "type": "MethodologyAgent"},
                {"name": self.experiment_agent.name, "type": "ExperimentEvaluatorAgent"},
                {"name": self.insight_agent.name, "type": "InsightGenerationAgent"},
                {"name": self.synthesizer_agent.name, "type": "SynthesizerAgent"},
            ],
            "pipeline_type": "Complete DAG (5 agents)",
            "parallel_agents": ["MethodologyAgent", "ExperimentEvaluatorAgent"],
            "workflow_stages": [
                "1. Resource Retrieval",
                "2. Parallel Analysis (Methodology + Experiment)",
                "3. Insight Generation",
                "4. Report Synthesis"
            ]
        }

    def validate_inputs(self, paper_input: str, input_type: str, user_background: str) -> Dict[str, Any]:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        errors = []

        # éªŒè¯è®ºæ–‡è¾“å…¥
        if not paper_input:
            errors.append("è®ºæ–‡è¾“å…¥ä¸èƒ½ä¸ºç©º")
        elif input_type == "file":
            import os

            if not os.path.exists(paper_input):
                errors.append(f"æ–‡ä»¶ä¸å­˜åœ¨: {paper_input}")
        elif input_type == "url":
            import re

            url_pattern = re.compile(
                r"^https?://"  # http:// or https://
                r"(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|"  # domain...
                r"localhost|"  # localhost...
                r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})"  # ...or ip
                r"(?::\d+)?"  # optional port
                r"(?:/?|[/?]\S+)$",
                re.IGNORECASE,
            )
            if not url_pattern.match(paper_input):
                errors.append("æ— æ•ˆçš„URLæ ¼å¼")

        # éªŒè¯è¾“å…¥ç±»å‹
        if input_type not in ["file", "url", "text"]:
            errors.append("è¾“å…¥ç±»å‹å¿…é¡»æ˜¯ fileã€url æˆ– text")

        # éªŒè¯ç”¨æˆ·èƒŒæ™¯
        if not self.synthesizer_agent.validate_user_background(user_background):
            errors.append("ç”¨æˆ·èƒŒæ™¯å¿…é¡»æ˜¯ beginnerã€intermediate æˆ– advanced")

        return {"valid": len(errors) == 0, "errors": errors}

    def get_supported_formats(self) -> Dict[str, List[str]]:
        """è·å–æ”¯æŒçš„æ ¼å¼"""
        return {
            "input_types": ["file", "url", "text"],
            "file_formats": [".pdf", ".docx", ".txt"],
            "user_backgrounds": ["beginner", "intermediate", "advanced"],
            "output_formats": ["markdown", "json"],
        }


def create_pipeline(config: Optional[Dict[str, Any]] = None) -> ScholarMindPipeline:
    """
    åˆ›å»ºScholarMindå·¥ä½œæµå®ä¾‹

    Args:
        config: å¯é€‰é…ç½®å‚æ•°

    Returns:
        ScholarMindPipeline: å·¥ä½œæµå®ä¾‹
    """
    # ç›®å‰å¿½ç•¥é…ç½®ï¼Œç›´æ¥åˆ›å»ºé»˜è®¤å®ä¾‹
    # æœªæ¥å¯ä»¥æ ¹æ®é…ç½®è‡ªå®šä¹‰å·¥ä½œæµ
    return ScholarMindPipeline()
