"""
ScholarMind Enhanced Pipeline
æ™ºè¯»ScholarMindå¢å¼ºå·¥ä½œæµ - ç»Ÿä¸€æ¶æ„å’Œé”™è¯¯å¤„ç†
"""

import asyncio
import time
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

from agentscope import pipeline
from agentscope.message import Msg

from ..agents.experiment_evaluator_agent import ExperimentEvaluatorAgent
from ..agents.insight_generation_agent import InsightGenerationAgent
from ..agents.methodology_agent import MethodologyAgent
from ..agents.resource_retrieval_agent import ResourceRetrievalAgent
from ..agents.synthesizer_agent import SynthesizerAgent
from ..utils.error_handler import safe_execute, with_error_handling
from ..utils.logger import pipeline_logger
from ..utils.message_utils import MessageUtils


class ScholarMindEnhancedPipeline:
    """ScholarMindå¢å¼ºå·¥ä½œæµ - ç»Ÿä¸€æ¶æ„å’Œé”™è¯¯å¤„ç†"""

    def __init__(self):
        """åˆå§‹åŒ–å¢å¼ºå·¥ä½œæµ"""
        pipeline_logger.info("ğŸš€ åˆå§‹åŒ–ScholarMindå¢å¼ºå·¥ä½œæµ...")

        # åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼ˆä½¿ç”¨æ–°çš„åŸºç±»æ¶æ„ï¼‰
        self.resource_agent = ResourceRetrievalAgent()
        self.methodology_agent = MethodologyAgent()
        self.experiment_agent = ExperimentEvaluatorAgent()
        self.insight_agent = InsightGenerationAgent()
        self.synthesizer_agent = SynthesizerAgent()

        # å·¥ä½œæµçŠ¶æ€
        self._pipeline_status = {
            "initialized": True,
            "agents_ready": False,
            "last_run": None,
            "total_runs": 0,
            "successful_runs": 0,
            "failed_runs": 0,
        }

        pipeline_logger.info("âœ… å¢å¼ºå·¥ä½œæµåˆå§‹åŒ–å®Œæˆï¼ˆ5ä¸ªæ™ºèƒ½ä½“å®Œæ•´DAGï¼‰")

    @with_error_handling(fallback_value={"success": False, "error": "å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥"})
    async def initialize_agents(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ‰€æœ‰æ™ºèƒ½ä½“"""
        if self._pipeline_status["agents_ready"]:
            return {"success": True, "message": "æ™ºèƒ½ä½“å·²åˆå§‹åŒ–"}

        try:
            # é¢„çƒ­æ‰€æœ‰æ™ºèƒ½ä½“æ¨¡å‹
            agents = [
                self.resource_agent,
                self.methodology_agent,
                self.experiment_agent,
                self.insight_agent,
                self.synthesizer_agent,
            ]

            for agent in agents:
                if hasattr(agent, "_ensure_model_initialized"):
                    await agent._ensure_model_initialized()
                    pipeline_logger.info(f"âœ… {agent.name} æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

            self._pipeline_status["agents_ready"] = True
            return {"success": True, "message": "æ‰€æœ‰æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ"}

        except Exception as e:
            pipeline_logger.error(f"âŒ æ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    @with_error_handling(fallback_value={"success": False, "error": "è®ºæ–‡å¤„ç†å¤±è´¥"})
    async def process_paper(
        self,
        paper_input: str,
        input_type: str = "file",
        user_background: str = "intermediate",
        save_report: bool = True,
        output_format: str = "markdown",
        output_language: str = "zh",
        progress_callback: Optional[Callable] = None,
    ) -> Dict[str, Any]:
        """
        å¢å¼ºçš„è®ºæ–‡å¤„ç†æµç¨‹ï¼ˆ5ä¸ªæ™ºèƒ½ä½“å®Œæ•´DAGï¼‰

        Args:
            paper_input: è®ºæ–‡è¾“å…¥ï¼ˆæ–‡ä»¶è·¯å¾„ã€URLæˆ–æ–‡æœ¬ï¼‰
            input_type: è¾“å…¥ç±»å‹ï¼ˆfileã€urlã€textï¼‰
            user_background: ç”¨æˆ·èƒŒæ™¯ï¼ˆbeginnerã€intermediateã€advancedï¼‰
            save_report: æ˜¯å¦ä¿å­˜æŠ¥å‘Š
            output_format: è¾“å‡ºæ ¼å¼ï¼ˆmarkdownã€jsonï¼‰
            output_language: è¾“å‡ºè¯­è¨€ï¼ˆzhã€enï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœ
        """
        start_time = time.time()

        # æ›´æ–°å·¥ä½œæµçŠ¶æ€
        self._pipeline_status["last_run"] = time.time()
        self._pipeline_status["total_runs"] += 1

        try:
            # åˆå§‹åŒ–æ™ºèƒ½ä½“
            await self.initialize_agents()

            # éªŒè¯è¾“å…¥å‚æ•°
            validation_result = self.validate_inputs(paper_input, input_type, user_background)
            if not validation_result["valid"]:
                return {
                    "success": False,
                    "error": f"è¾“å…¥éªŒè¯å¤±è´¥: {'; '.join(validation_result['errors'])}",
                    "stage": "validation",
                }

            # æ­¥éª¤1ï¼šèµ„æºæ£€ç´¢
            resource_result = await self._execute_stage(
                stage_name="resource_retrieval",
                stage_func=self._process_resource_retrieval,
                progress_callback=progress_callback,
                progress_message="ğŸ“– æ­¥éª¤ 1/4ï¼šæ­£åœ¨æ£€ç´¢å’Œè§£æè®ºæ–‡...",
                paper_input=paper_input,
                input_type=input_type,
            )

            if not resource_result["success"]:
                self._pipeline_status["failed_runs"] += 1
                return resource_result

            # æ­¥éª¤2ï¼šå¹¶è¡Œå¤„ç†ï¼ˆæ–¹æ³•è®ºåˆ†æ + å®éªŒè¯„ä¼°ï¼‰
            methodology_result, experiment_result = await self._execute_parallel_stage(
                stage_name="parallel_analysis",
                progress_callback=progress_callback,
                progress_message="ğŸ”¬ æ­¥éª¤ 2/4ï¼šå¹¶è¡Œåˆ†æè®ºæ–‡æ–¹æ³•è®ºå’Œå®éªŒè¯„ä¼°...",
                paper_content=resource_result["data"]["paper_content"],
                output_language=output_language,
            )

            # æ­¥éª¤3ï¼šæ´å¯Ÿç”Ÿæˆ
            insight_result = await self._execute_stage(
                stage_name="insight_generation",
                stage_func=self._process_insight_generation,
                progress_callback=progress_callback,
                progress_message="ğŸ’¡ æ­¥éª¤ 3/4ï¼šç”Ÿæˆæ‰¹åˆ¤æ€§æ´å¯Ÿå’Œç ”ç©¶å»ºè®®...",
                paper_content=resource_result["data"]["paper_content"],
                methodology_analysis=(
                    methodology_result.get("data") if methodology_result["success"] else None
                ),
                experiment_evaluation=(
                    experiment_result.get("data") if experiment_result["success"] else None
                ),
                output_language=output_language,
            )

            # æ­¥éª¤4ï¼šç»¼åˆæŠ¥å‘Šç”Ÿæˆ
            synthesizer_result = await self._execute_stage(
                stage_name="synthesizer",
                stage_func=self._process_synthesizer,
                progress_callback=progress_callback,
                progress_message="ğŸ“ æ­¥éª¤ 4/4ï¼šç»¼åˆç”Ÿæˆä¸ªæ€§åŒ–è§£è¯»æŠ¥å‘Š...",
                resource_data=resource_result["data"],
                methodology_analysis=(
                    methodology_result.get("data") if methodology_result["success"] else None
                ),
                experiment_evaluation=(
                    experiment_result.get("data") if experiment_result["success"] else None
                ),
                insight_analysis=insight_result.get("data") if insight_result["success"] else None,
                user_background=user_background,
                output_language=output_language,
            )

            if not synthesizer_result["success"]:
                self._pipeline_status["failed_runs"] += 1
                return synthesizer_result

            # ä¿å­˜æŠ¥å‘Š
            report_path = None
            if save_report:
                report_path = await self._save_report_safe(
                    synthesizer_result["data"], output_format, output_language
                )

            # è®¡ç®—æ€»å¤„ç†æ—¶é—´
            total_time = time.time() - start_time
            self._pipeline_status["successful_runs"] += 1

            # å‘é€å®Œæˆæ¶ˆæ¯
            if progress_callback:
                await progress_callback(f"âœ¨ è®ºæ–‡åˆ†æå®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")

            # æ„å»ºæœ€ç»ˆç»“æœ
            result = self._build_final_result(
                total_time=total_time,
                resource_result=resource_result,
                methodology_result=methodology_result,
                experiment_result=experiment_result,
                insight_result=insight_result,
                synthesizer_result=synthesizer_result,
                report_path=report_path,
                user_background=user_background,
                input_type=input_type,
                output_format=output_format,
                output_language=output_language,
            )

            pipeline_logger.info(f"âœ… è®ºæ–‡å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
            return result

        except Exception as e:
            self._pipeline_status["failed_runs"] += 1
            total_time = time.time() - start_time
            pipeline_logger.error(f"âŒ è®ºæ–‡å¤„ç†å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": total_time,
                "stage": "unknown",
            }

    async def _execute_stage(
        self,
        stage_name: str,
        stage_func: Callable,
        progress_callback: Optional[Callable] = None,
        progress_message: str = None,
        **kwargs,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå¤„ç†é˜¶æ®µ"""
        try:
            if progress_callback and progress_message:
                await progress_callback(progress_message)
            else:
                pipeline_logger.info(f"æ‰§è¡Œé˜¶æ®µ: {stage_name}")

            result = await stage_func(**kwargs)

            if not result.get("success", False):
                pipeline_logger.warning(
                    f"âš ï¸ {stage_name} é˜¶æ®µå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                )

            return result

        except Exception as e:
            pipeline_logger.error(f"âŒ {stage_name} é˜¶æ®µå¼‚å¸¸: {e}")
            return {"success": False, "error": str(e), "stage": stage_name}

    async def _execute_parallel_stage(
        self,
        stage_name: str,
        progress_callback: Optional[Callable] = None,
        progress_message: str = None,
        **kwargs,
    ) -> tuple:
        """æ‰§è¡Œå¹¶è¡Œå¤„ç†é˜¶æ®µ"""
        try:
            if progress_callback and progress_message:
                await progress_callback(progress_message)
            else:
                pipeline_logger.info(f"æ‰§è¡Œå¹¶è¡Œé˜¶æ®µ: {stage_name}")

            parallel_start = time.time()

            # å¹¶è¡Œæ‰§è¡Œæ–¹æ³•è®ºåˆ†æå’Œå®éªŒè¯„ä¼°
            methodology_task = self._process_methodology_analysis(
                kwargs["paper_content"], kwargs["output_language"]
            )
            experiment_task = self._process_experiment_evaluation(
                kwargs["paper_content"], kwargs["output_language"]
            )

            methodology_result, experiment_result = await asyncio.gather(
                methodology_task, experiment_task, return_exceptions=True
            )

            parallel_time = time.time() - parallel_start

            # å¤„ç†å¼‚å¸¸ç»“æœ
            if isinstance(methodology_result, Exception):
                methodology_result = {"success": False, "error": str(methodology_result)}
            if isinstance(experiment_result, Exception):
                experiment_result = {"success": False, "error": str(experiment_result)}

            if progress_callback:
                await progress_callback(f"âœ… å¹¶è¡Œåˆ†æå®Œæˆï¼Œè€—æ—¶: {parallel_time:.1f}ç§’")

            return methodology_result, experiment_result

        except Exception as e:
            pipeline_logger.error(f"âŒ {stage_name} å¹¶è¡Œé˜¶æ®µå¼‚å¸¸: {e}")
            error_result = {"success": False, "error": str(e)}
            return error_result, error_result

    async def _process_parallel_analysis(self, paper_content: dict, output_language: str) -> tuple:
        """å¹¶è¡Œåˆ†ææ–¹æ³•ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰"""
        return await self._execute_parallel_stage(
            stage_name="parallel_analysis",
            paper_content=paper_content,
            output_language=output_language,
        )

    def validate_inputs(
        self, paper_input: str, input_type: str, user_background: str
    ) -> Dict[str, Any]:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        errors = []

        # éªŒè¯è®ºæ–‡è¾“å…¥
        if not paper_input or not paper_input.strip():
            errors.append("è®ºæ–‡è¾“å…¥ä¸èƒ½ä¸ºç©º")

        # éªŒè¯è¾“å…¥ç±»å‹
        valid_types = ["file", "url", "text"]
        if input_type not in valid_types:
            errors.append(f"æ— æ•ˆçš„è¾“å…¥ç±»å‹: {input_type}ï¼Œæ”¯æŒçš„ç±»å‹: {valid_types}")

        # éªŒè¯ç”¨æˆ·èƒŒæ™¯
        valid_backgrounds = ["beginner", "intermediate", "advanced"]
        if user_background not in valid_backgrounds:
            errors.append(f"æ— æ•ˆçš„ç”¨æˆ·èƒŒæ™¯: {user_background}ï¼Œæ”¯æŒçš„èƒŒæ™¯: {valid_backgrounds}")

        # æ–‡ä»¶ç±»å‹ç‰¹å®šéªŒè¯
        if input_type == "file":
            if not Path(paper_input).exists():
                pipeline_logger.error_path("æ–‡ä»¶éªŒè¯", paper_input, "æ–‡ä»¶ä¸å­˜åœ¨")
                errors.append(f"æ–‡ä»¶ä¸å­˜åœ¨: {paper_input}")
            elif not paper_input.lower().endswith((".pdf", ".txt")):
                pipeline_logger.warning_path("æ–‡ä»¶æ ¼å¼éªŒè¯", paper_input, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                errors.append(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {paper_input}ï¼Œæ”¯æŒçš„æ ¼å¼: .pdf, .txt")

        return {"valid": len(errors) == 0, "errors": errors}

    async def _process_resource_retrieval(
        self, paper_input: str, input_type: str
    ) -> Dict[str, Any]:
        """å¤„ç†èµ„æºæ£€ç´¢é˜¶æ®µ"""
        try:
            input_data = {"paper_input": paper_input, "input_type": input_type}
            message = MessageUtils.create_user_message(input_data)

            response = await self.resource_agent.reply(message)
            return MessageUtils.parse_agent_response(response)

        except Exception as e:
            return {"success": False, "error": f"èµ„æºæ£€ç´¢å¤±è´¥: {str(e)}"}

    async def _process_methodology_analysis(
        self, paper_content: Dict[str, Any], output_language: str
    ) -> Dict[str, Any]:
        """å¤„ç†æ–¹æ³•è®ºåˆ†æé˜¶æ®µ"""
        try:
            input_data = {"paper_content": paper_content, "output_language": output_language}
            message = MessageUtils.create_user_message(input_data)

            response = await self.methodology_agent.reply(message)
            return MessageUtils.parse_agent_response(response)

        except Exception as e:
            return {"success": False, "error": f"æ–¹æ³•è®ºåˆ†æå¤±è´¥: {str(e)}"}

    async def _process_experiment_evaluation(
        self, paper_content: Dict[str, Any], output_language: str
    ) -> Dict[str, Any]:
        """å¤„ç†å®éªŒè¯„ä¼°é˜¶æ®µ"""
        try:
            input_data = {"paper_content": paper_content, "output_language": output_language}
            message = MessageUtils.create_user_message(input_data)

            response = await self.experiment_agent.reply(message)
            return MessageUtils.parse_agent_response(response)

        except Exception as e:
            return {"success": False, "error": f"å®éªŒè¯„ä¼°å¤±è´¥: {str(e)}"}

    async def _process_insight_generation(
        self,
        paper_content: Dict[str, Any],
        methodology_analysis: Optional[Dict[str, Any]],
        experiment_evaluation: Optional[Dict[str, Any]],
        output_language: str,
    ) -> Dict[str, Any]:
        """å¤„ç†æ´å¯Ÿç”Ÿæˆé˜¶æ®µ"""
        try:
            input_data = {
                "paper_content": paper_content,
                "methodology_analysis": methodology_analysis,
                "experiment_evaluation": experiment_evaluation,
                "output_language": output_language,
            }
            message = MessageUtils.create_user_message(input_data)

            response = await self.insight_agent.reply(message)
            return MessageUtils.parse_agent_response(response)

        except Exception as e:
            return {"success": False, "error": f"æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}"}

    async def _process_synthesizer(
        self,
        resource_data: Dict[str, Any],
        methodology_analysis: Optional[Dict[str, Any]],
        experiment_evaluation: Optional[Dict[str, Any]],
        insight_analysis: Optional[Dict[str, Any]],
        user_background: str,
        output_language: str,
    ) -> Dict[str, Any]:
        """å¤„ç†ç»¼åˆæŠ¥å‘Šç”Ÿæˆé˜¶æ®µ"""
        try:
            input_data = {
                "paper_content": resource_data["paper_content"],
                "methodology_analysis": methodology_analysis,
                "experiment_evaluation": experiment_evaluation,
                "insight_analysis": insight_analysis,
                "user_background": user_background,
                "output_language": output_language,
            }
            message = MessageUtils.create_user_message(input_data)

            response = await self.synthesizer_agent.reply(message)
            return MessageUtils.parse_agent_response(response)

        except Exception as e:
            return {"success": False, "error": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"}

    async def _save_report_safe(
        self, report_data: Dict[str, Any], output_format: str, output_language: str
    ) -> Optional[str]:
        """å®‰å…¨çš„æŠ¥å‘Šä¿å­˜"""
        try:
            return self._save_report(report_data, output_format, output_language)
        except Exception as e:
            pipeline_logger.error(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
            return None

    def _save_report(
        self, report_data: Dict[str, Any], output_format: str, output_language: str
    ) -> Optional[str]:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            import json
            import os
            from datetime import datetime

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = "outputs"
            os.makedirs(output_dir, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            title_safe = "".join(
                c
                for c in report_data.get("title", "report")[:50]
                if c.isalnum() or c in (" ", "-", "_")
            ).rstrip()
            filename = f"{title_safe}_{timestamp}.{output_format}"
            filepath = os.path.join(output_dir, filename)

            # ä¿å­˜æŠ¥å‘Š
            if output_format == "json":
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(report_data, f, ensure_ascii=False, indent=2)
            else:  # markdown
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(f"# {report_data.get('title', 'è®ºæ–‡åˆ†ææŠ¥å‘Š')}\n\n")
                    f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                    f.write(f"**è¯­è¨€**: {output_language}\n\n")
                    f.write("---\n\n")

                    if report_data.get("summary"):
                        f.write("## æ‘˜è¦\n\n")
                        f.write(f"{report_data['summary']}\n\n")

                    if report_data.get("key_contributions"):
                        f.write("## ä¸»è¦è´¡çŒ®\n\n")
                        for i, contribution in enumerate(report_data["key_contributions"], 1):
                            f.write(f"{i}. {contribution}\n")
                        f.write("\n")

                    if report_data.get("insights"):
                        f.write("## å…³é”®æ´å¯Ÿ\n\n")
                        for i, insight in enumerate(report_data["insights"], 1):
                            f.write(f"{i}. {insight}\n")
                        f.write("\n")

            pipeline_logger.info(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {filepath}")
            return filepath

        except Exception as e:
            pipeline_logger.error(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
            return None

    def _build_final_result(
        self,
        total_time: float,
        resource_result: Dict[str, Any],
        methodology_result: Dict[str, Any],
        experiment_result: Dict[str, Any],
        insight_result: Dict[str, Any],
        synthesizer_result: Dict[str, Any],
        report_path: Optional[str],
        user_background: str,
        input_type: str,
        output_format: str,
        output_language: str,
    ) -> Dict[str, Any]:
        """æ„å»ºæœ€ç»ˆç»“æœ"""

        # å®‰å…¨åœ°è·å–å„é˜¶æ®µçš„å¤„ç†æ—¶é—´
        def safe_get_processing_time(result, default=0):
            if isinstance(result, dict):
                # å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
                if "processing_time" in result:
                    return result["processing_time"]
                elif (
                    "data" in result
                    and isinstance(result["data"], dict)
                    and "processing_time" in result["data"]
                ):
                    return result["data"]["processing_time"]
            return default

        return {
            "success": True,
            "message": "è®ºæ–‡å¤„ç†å®Œæˆ",
            "processing_time": total_time,
            "stages": {
                "resource_retrieval": {
                    "success": True,
                    "processing_time": safe_get_processing_time(resource_result),
                    "paper_title": resource_result.get("data", {})
                    .get("paper_content", {})
                    .get("metadata", {})
                    .get("title", "Unknown"),
                },
                "methodology_analysis": {
                    "success": methodology_result.get("success", False),
                    "processing_time": safe_get_processing_time(methodology_result),
                },
                "experiment_evaluation": {
                    "success": experiment_result.get("success", False),
                    "processing_time": safe_get_processing_time(experiment_result),
                },
                "insight_generation": {
                    "success": insight_result.get("success", False),
                    "processing_time": safe_get_processing_time(insight_result),
                },
                "synthesizer": {
                    "success": synthesizer_result.get("success", True),
                    "processing_time": safe_get_processing_time(synthesizer_result),
                    "report_title": synthesizer_result.get("data", {}).get("title", "Unknown"),
                },
            },
            "outputs": {
                "paper_content": resource_result.get("data", {}).get("paper_content"),
                "methodology_analysis": (
                    methodology_result.get("data") if methodology_result.get("success") else None
                ),
                "experiment_evaluation": (
                    experiment_result.get("data") if experiment_result.get("success") else None
                ),
                "insight_analysis": (
                    insight_result.get("data") if insight_result.get("success") else None
                ),
                "report": synthesizer_result.get("data"),
                "report_path": report_path,
            },
            "metadata": {
                "user_background": user_background,
                "input_type": input_type,
                "output_format": output_format,
                "output_language": output_language,
            },
        }

    def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        return {
            **self._pipeline_status,
            "agents": [
                self.resource_agent.name,
                self.methodology_agent.name,
                self.experiment_agent.name,
                self.insight_agent.name,
                self.synthesizer_agent.name,
            ],
            "pipeline_type": "Complete DAG (5 agents)",
            "workflow_stages": [
                "resource_retrieval",
                "parallel_analysis",
                "insight_generation",
                "synthesizer",
            ],
            "success_rate": (
                self._pipeline_status["successful_runs"]
                / max(self._pipeline_status["total_runs"], 1)
                * 100
            ),
        }


# ä¿æŒå‘åå…¼å®¹çš„å·¥å‚å‡½æ•°
def create_pipeline() -> ScholarMindEnhancedPipeline:
    """åˆ›å»ºScholarMindå·¥ä½œæµå®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰"""
    return ScholarMindEnhancedPipeline()
